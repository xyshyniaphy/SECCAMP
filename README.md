# SECCAMP - Private Campsite Search AI Agent

A batch automation system that searches and analyzes private campsite-suitable land from Japanese real estate websites.

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)

## Features

- **Web Scraping** - Scrapes 7 major Japanese real estate sites
- **Page-Level Caching** - SQLite-based cache with TTL (6h/7d/30d) and compression
- **Rate Limiting** - Real-time rate limiting with automatic waiting
- **AI Scoring** - 100-point campsite suitability evaluation (6 criteria)
- **Daily Blog** - Jinja2 template-based Markdown generation
- **Hugo Build** - Static site generation
- **Auto Deploy** - Git push to GitHub Pages

## Current Status

### Implemented âœ…

- Docker multi-stage build with uv package manager
- SQLite database with complete schema (10 tables)
- Page-level caching system with compression
- Rate limiting per site with real-time tracking
- Base scraper class with Selenium integration
- Database ORM with SQLAlchemy models
- Development mode with hot-reload (`./run_dev.sh`)
- **AthomeScraper** - Scrape-only for debugging (saves HTML for inspection)

### Pending ğŸš§

- AthomeScraper parsing logic implementation
- Additional site scrapers (suumo, ieichiba, etc.)
- AI scoring engine implementation
- Blog generation with Jinja2 templates
- Hugo site building
- Git auto-push
- GitHub Actions workflow

## Quick Start

```bash
# Build
./build.sh

# Run in dev mode (hot-reload, no rebuild needed)
./run_dev.sh full

# Run specific mode
./run_dev.sh scrape

# Production run
./run_full.sh
```

## Project Structure

```
seccamp/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Entry point
â”‚   â”œâ”€â”€ config.py            # Configuration from environment
â”‚   â”œâ”€â”€ config/              # Site configuration
â”‚   â”‚   â”œâ”€â”€ site_config.py   # SiteConfig loader
â”‚   â”‚   â””â”€â”€ sites.json       # Site URLs, selectors, rate limits
â”‚   â”œâ”€â”€ database/            # Database layer
â”‚   â”‚   â”œâ”€â”€ models.py        # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ operations.py    # DatabaseManager
â”‚   â””â”€â”€ scrapers/            # Web scraping
â”‚       â”œâ”€â”€ base_scraper.py  # Abstract base class
â”‚       â”œâ”€â”€ athome_scraper.py # AtHome scraper (scrape-only for debugging)
â”‚       â”œâ”€â”€ cache_manager.py # Page caching
â”‚       â”œâ”€â”€ rate_limiter.py  # Rate limiting
â”‚       â””â”€â”€ url_normalizer.py # URL normalization
â”œâ”€â”€ data/                    # Volume mapped
â”‚   â”œâ”€â”€ seccamp.db           # SQLite database
â”‚   â”œâ”€â”€ logs/                # Log files
â”‚   â”œâ”€â”€ debug/               # Scraped HTML for debugging
â”‚   â””â”€â”€ hugo_site/           # Hugo site
â”œâ”€â”€ refer/                   # Reference documentation
â”œâ”€â”€ Dockerfile               # Multi-stage build with uv
â”œâ”€â”€ docker-compose.yml       # Production
â”œâ”€â”€ docker-compose.dev.yml   # Development (hot-reload)
â””â”€â”€ run_*.sh                 # Convenience scripts
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  URL Request                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
    [Check Cache]
    â”œâ”€ HIT â†’ Return cached (0.001s)
    â””â”€ MISS â†’ [Check Rate Limit]
                  â”œâ”€ OK â†’ Scrape
                  â””â”€ WAIT â†’ Scrape
                      â†“
                 [Store in Cache]
                      â†“
                 [Parse & Save to DB]
```

## Development

### Requirements

- Docker 24.0+
- Python 3.12+ (in container)
- Chrome + ChromeDriver (in container)
- Hugo Extended 0.120+ (in container)

### Environment Variables

```bash
# .env file
LOG_LEVEL=INFO
GITHUB_TOKEN=ghp_xxxxx
GITHUB_REPO=username/seccamp
GITHUB_USER=Your Name
GITHUB_EMAIL=your@email.com
HUGO_BASE_URL=https://username.github.io/seccamp/

# Scraping limits (for debugging)
MAX_DETAIL_PAGES=1  # Limit detail pages scraped per run
```

### Dev vs Production

| Mode | Compose File | Source Code | Rebuild |
|------|--------------|-------------|---------|
| Production | `docker-compose.yml` | Built into image | Required after changes |
| Dev | `docker-compose.dev.yml` | Mounted `./app` | Not needed |

### Debugging Scrapers

When `MAX_DETAIL_PAGES` is set, scraped HTML is saved for inspection:

```bash
# Run scraper
./run_dev.sh scrape

# Inspect output
ls -la data/debug/$(date +%Y-%m-%d)/
# Contains: athome_list.html, athome_detail_*.html
```

Use the saved HTML to understand the structure before implementing parsing logic.

## Database Schema

### Core Tables

| Table | Purpose |
|-------|---------|
| `rate_limits` | Rate limit config per site |
| `rate_limit_tracker` | Request history |
| `cache_entries` | URL index for cache lookup |
| `scraped_pages_cache` | Cached HTML content |
| `properties` | Master property data |
| `ai_scores` | AI analysis scores |
| `scraping_logs` | Scraping session logs |
| `daily_blogs` | Blog metadata |

### Cache TTL

- **List pages**: 6 hours
- **Detail pages**: 7 days
- **Images**: 30 days

## License

Apache License 2.0 - see [LICENSE](LICENSE) for details.

---

# SECCAMPï¼ˆãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚­ãƒ£ãƒ³ãƒ—å ´æ¢ç´¢AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰

æ—¥æœ¬ã®ä¸å‹•ç”£ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚­ãƒ£ãƒ³ãƒ—å ´ã«é©ã—ãŸåœŸåœ°ã‚’è‡ªå‹•æ¤œç´¢ãƒ»åˆ†æã™ã‚‹ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ ã€‚

**ç‰ˆ:** 5.0 (AthomeScraper in Development)
**ä½œæˆæ—¥:** 2025å¹´12æœˆ24æ—¥
**æœ€çµ‚æ›´æ–°:** 2025å¹´12æœˆ24æ—¥

## å®Ÿè£…çŠ¶æ³

### å®Ÿè£…æ¸ˆã¿ âœ…

- Dockerãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ (uvãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼)
- SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (å®Œå…¨ã‚¹ã‚­ãƒ¼ãƒ10ãƒ†ãƒ¼ãƒ–ãƒ«)
- ãƒšãƒ¼ã‚¸ãƒ¬ãƒ™ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ  (TTL 6h/7d/30d, åœ§ç¸®æ©Ÿèƒ½)
- ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚·ã‚¹ãƒ†ãƒ  (ã‚µã‚¤ãƒˆåˆ¥ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¿½è·¡)
- BaseScraperã‚¯ãƒ©ã‚¹ (Seleniumçµ±åˆ)
- DatabaseManager (SQLAlchemy ORM)
- é–‹ç™ºãƒ¢ãƒ¼ãƒ‰ (ãƒ›ãƒƒãƒˆãƒªãƒ­ãƒ¼ãƒ‰)
- **AthomeScraper** - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè£…ä¸­ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨HTMLä¿å­˜ï¼‰

### æœªå®Ÿè£… ğŸš§

- AthomeScraper ãƒ‘ãƒ¼ã‚¹ãƒ­ã‚¸ãƒƒã‚¯
- ä»–ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ (suumo, ieichibaç­‰)
- AIã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
- ãƒ–ãƒ­ã‚°ç”Ÿæˆ (Jinja2)
- Hugoã‚µã‚¤ãƒˆãƒ“ãƒ«ãƒ‰
- Gitè‡ªå‹•ãƒ—ãƒƒã‚·ãƒ¥
- GitHub Actions

---

**ä½œæˆè€…:** SECCAMPé–‹ç™ºãƒãƒ¼ãƒ 
**ãƒ©ã‚¤ã‚»ãƒ³ã‚¹:** Apache 2.0
